{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1HlXKF9q4jqAoDTZdIUwYTMpKw_qc0i7j",
      "authorship_tag": "ABX9TyMl3TDevfW6K1PXJQJQuxRg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/putricha/college-machine-learning/blob/main/PraktikumBAB1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEUDWb_HfotM"
      },
      "outputs": [],
      "source": [
        "def norm_data(data):\n",
        "\n",
        "  data_max = max(data)\n",
        "  data_min = min(data)\n",
        "  data_len = len(data)\n",
        "\n",
        "  for i in range(0,data_len):\n",
        "    data[i] = (data[i] - data_min) / (data_max - data_min)\n",
        "\n",
        "\n",
        "  return data\n",
        "\n",
        "\n",
        "  # contoh penggunaan\n",
        "  data=[10, 11, 12, 14, 16]\n",
        "  n_data = norm_data(data)\n",
        "  print(n_data)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def norm_data(data):\n",
        "  '''\n",
        "  Melakukan normalisasi data.\n",
        "\n",
        "  Parameters:\n",
        "      data (list): Data yang akan dinormalisasi.\n",
        "\n",
        "  Returns:\n",
        "      list: Data yang sudah dinormalisasi.\n",
        "\n",
        "  '''\n",
        "\n",
        "  data_max = max(data)\n",
        "  data_min = min(data)\n",
        "  data_len = len(data)\n",
        "\n",
        "  for i in range(0, data_len):\n",
        "    data[i] = (data[i] - data_min) / (data_max - data_min)\n",
        "\n",
        "  return data\n",
        "\n",
        "# Contoh Penggunaan\n",
        "data = [10, 11, 12, 14, 16]\n",
        "n_data = norm_data(data) # Melakukan normalisasi\n",
        "print(n_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyFA0z3OhYX7",
        "outputId": "383f9aa5-82da-4d54-9055-b0d185dfa025"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.0, 0.16666666666666666, 0.3333333333333333, 0.6666666666666666, 1.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "np.set_printoptions(precision=6)\n",
        "np.set_printoptions(suppress=True)  #hilangkan nilai e\n",
        "\n",
        "# Kita akan membentuk data\n",
        "# Hal ini dikarenakan, scikit-learn hanya menerima input\n",
        "# dalam bentuk -dimensional array\n",
        "\n",
        "data = [\n",
        "    [100, 0.0001],\n",
        "    [50, 0.05],\n",
        "    [30, 0.003]\n",
        "]\n",
        "\n",
        "\n",
        "# Ubah ke bentuk numpy n-dimensional array\n",
        "data = np.asarray(data)\n",
        "print(\"Data Asli\")\n",
        "print(data)\n",
        "\n",
        "# Mendefinisikan obyek MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "#Transformasikan data\n",
        "\n",
        "scaled = scaler.fit_transform(data)\n",
        "print(\"Data Normalisasi\")\n",
        "print(scaled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5O80o7tnh7AF",
        "outputId": "e1bd587d-9fe8-4a4a-c1f9-dab93a9630ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Asli\n",
            "[[100.       0.0001]\n",
            " [ 50.       0.05  ]\n",
            " [ 30.       0.003 ]]\n",
            "Data Normalisasi\n",
            "[[1.       0.      ]\n",
            " [0.285714 1.      ]\n",
            " [0.       0.058116]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "np.set_printoptions(precision=6) #bulatkan 4 angkat koma\n",
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "#kita akan membentuk data\n",
        "#hal ini dikarenakan, scikit-learn hanya menerima input\n",
        "#dalam bentuk -dimensional array\n",
        "\n",
        "data = [\n",
        "    [100, 0.0001],\n",
        "    [50, 0.05],\n",
        "    [30, 0.003]\n",
        "]\n",
        "\n",
        "# Ubah ke bentuk numpy n-dimensional array\n",
        "data = np.asarray(data)\n",
        "print(\"Data Asli\")\n",
        "print(data)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "# Transformasikan data\n",
        "scaled = scaler.fit_transform(data)\n",
        "print(\"Data Standarisasi\")\n",
        "print(scaled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3M89FhikwYi",
        "outputId": "b4c8079a-334f-4d84-dab3-e4a7cc0c784d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Asli\n",
            "[[100.       0.0001]\n",
            " [ 50.       0.05  ]\n",
            " [ 30.       0.003 ]]\n",
            "Data Standarisasi\n",
            "[[ 1.358732 -0.76956 ]\n",
            " [-0.339683  1.412317]\n",
            " [-1.019049 -0.642757]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "# Inisiasi Obyek Ordinal Encoder\n",
        "oe = OrdinalEncoder()\n",
        "\n",
        "# Definisikan data\n",
        "# dalam bentuk 2d\n",
        "\n",
        "# setiap kategori diberi nilai unik sebagai tanda pengenal\n",
        "\n",
        "data = [\n",
        "    ['Politeknik Negeri Malang'],\n",
        "    ['Politeknik Elektronika Negeri Surabaya'],\n",
        "    ['Politeknik Negeri Jakarta'],\n",
        "    ['Politeknik Negeri Semarang']\n",
        "]\n",
        "\n",
        "# Transformasi Ordinal Encoder\n",
        "transform_oe = oe.fit_transform(data)\n",
        "print(\"Data Asli\")\n",
        "print(data)\n",
        "\n",
        "print('Datwa Transformasi Ordinal Encoder')\n",
        "print(transform_oe)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmbkGMuRljtl",
        "outputId": "9fcd7ad3-9ab9-4937-8771-ed3e20769961"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Asli\n",
            "[['Politeknik Negeri Malang'], ['Politeknik Elektronika Negeri Surabaya'], ['Politeknik Negeri Jakarta'], ['Politeknik Negeri Semarang']]\n",
            "Datwa Transformasi Ordinal Encoder\n",
            "[[2.]\n",
            " [0.]\n",
            " [1.]\n",
            " [3.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from  sklearn.preprocessing import  OneHotEncoder\n",
        "\n",
        "# inisial objek ordinal encoder\n",
        "\n",
        "ohe = OneHotEncoder()\n",
        "\n",
        "# definisikan data\n",
        "# dalam bentuk 2d\n",
        "\n",
        "# setiap kategori diberi nilai unik sebagai tanda pengenal\n",
        "\n",
        "data = [\n",
        "    ['Politeknik Negeri Malang'],\n",
        "    ['Politeknik Elektronika Negeri Surabaya'],\n",
        "    ['Politeknik Negeri Jakarta'],\n",
        "    ['Politeknik Negeri Semarang']\n",
        "]\n",
        "\n",
        "# transformasi ordinal encoder\n",
        "\n",
        "transform_ohe= ohe.fit_transform(data)\n",
        "print(\"Data Asli\")\n",
        "print(data)\n",
        "\n",
        "print(\"Data Transformasi One Hot Encoder\")\n",
        "print(transform_ohe.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9lu0vDOmkph",
        "outputId": "26176310-107e-41b3-ad19-3e70ebec7ece"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Asli\n",
            "[['Politeknik Negeri Malang'], ['Politeknik Elektronika Negeri Surabaya'], ['Politeknik Negeri Jakarta'], ['Politeknik Negeri Semarang']]\n",
            "Data Transformasi One Hot Encoder\n",
            "[[0. 0. 1. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Inisiasi obyek Ordinal encooder\n",
        "de = OneHotEncoder(drop='first')\n",
        "\n",
        "# definisikan data\n",
        "#  dalam bentuk 2d\n",
        "\n",
        "data = [\n",
        "    ['Politeknik Negeri Malang'],\n",
        "    ['Politeknik Elektronika Negeri Surabaya'],\n",
        "    ['Politeknik Negeri Jakarta'],\n",
        "    ['Politeknik Negeri Semarang']\n",
        "]\n",
        "\n",
        "# transformasi ordinal encoder\n",
        "\n",
        "transform_de = de.fit_transform(data)\n",
        "print(\"Data Asli\")\n",
        "print(data)\n",
        "\n",
        "print(\"Data Transformasi One-Hot Encoding\")\n",
        "print(transform_de.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPKNHLbxnWFV",
        "outputId": "00b6bd00-ee81-4e61-9477-555d69b39e9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Asli\n",
            "[['Politeknik Negeri Malang'], ['Politeknik Elektronika Negeri Surabaya'], ['Politeknik Negeri Jakarta'], ['Politeknik Negeri Semarang']]\n",
            "Data Transformasi One-Hot Encoding\n",
            "[[0. 1. 0.]\n",
            " [0. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [\n",
        "    'the house had a tiny little mouse',\n",
        "    'the cat saw the mouse',\n",
        "    'the mouse ran away from the house',\n",
        "    'the cat finally ate the mouse',\n",
        "    'the end of the mouse story'\n",
        "]\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Inisialisasi obyek TFidVectorizer\n",
        "\n",
        "vect= TfidfVectorizer(stop_words='english')\n",
        "\n",
        "# pembobotan tf idf\n",
        "\n",
        "resp = vect.fit_transform(corpus)\n",
        "print(resp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvlLtAG6oHPL",
        "outputId": "ad2e1700-0574-4529-a03d-eea2a4a8757e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 7)\t0.2808823162882302\n",
            "  (0, 6)\t0.5894630806320427\n",
            "  (0, 11)\t0.5894630806320427\n",
            "  (0, 5)\t0.47557510189256375\n",
            "  (1, 9)\t0.7297183669435993\n",
            "  (1, 2)\t0.5887321837696324\n",
            "  (1, 7)\t0.3477147117091919\n",
            "  (2, 1)\t0.5894630806320427\n",
            "  (2, 8)\t0.5894630806320427\n",
            "  (2, 7)\t0.2808823162882302\n",
            "  (2, 5)\t0.47557510189256375\n",
            "  (3, 0)\t0.5894630806320427\n",
            "  (3, 4)\t0.5894630806320427\n",
            "  (3, 2)\t0.47557510189256375\n",
            "  (3, 7)\t0.2808823162882302\n",
            "  (4, 10)\t0.6700917930430479\n",
            "  (4, 3)\t0.6700917930430479\n",
            "  (4, 7)\t0.3193023297639811\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [\n",
        "    'the house had a tiny little mouse',\n",
        "    'the cat saw the mouse',\n",
        "    'the mouse ran away from the house',\n",
        "    'the cat finally ate the mouse',\n",
        "    'the end of the mouse story'\n",
        "]\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Inisialisasi obyek TFidVectorizer\n",
        "\n",
        "vect= TfidfVectorizer(stop_words='english')\n",
        "\n",
        "# pembobotan tf idf\n",
        "\n",
        "resp = vect.fit_transform(corpus)\n",
        "print(resp)\n",
        "print(resp.toarray())\n",
        "\n",
        "# cetak token hasil stopword\n",
        "print('Hasil Token')\n",
        "print(vect.get_feature_names_out())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6mHd9vYo_Ov",
        "outputId": "61e5b1b6-8461-43b6-9255-d8a3fbf87e13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 7)\t0.2808823162882302\n",
            "  (0, 6)\t0.5894630806320427\n",
            "  (0, 11)\t0.5894630806320427\n",
            "  (0, 5)\t0.47557510189256375\n",
            "  (1, 9)\t0.7297183669435993\n",
            "  (1, 2)\t0.5887321837696324\n",
            "  (1, 7)\t0.3477147117091919\n",
            "  (2, 1)\t0.5894630806320427\n",
            "  (2, 8)\t0.5894630806320427\n",
            "  (2, 7)\t0.2808823162882302\n",
            "  (2, 5)\t0.47557510189256375\n",
            "  (3, 0)\t0.5894630806320427\n",
            "  (3, 4)\t0.5894630806320427\n",
            "  (3, 2)\t0.47557510189256375\n",
            "  (3, 7)\t0.2808823162882302\n",
            "  (4, 10)\t0.6700917930430479\n",
            "  (4, 3)\t0.6700917930430479\n",
            "  (4, 7)\t0.3193023297639811\n",
            "[[0.       0.       0.       0.       0.       0.475575 0.589463 0.280882\n",
            "  0.       0.       0.       0.589463]\n",
            " [0.       0.       0.588732 0.       0.       0.       0.       0.347715\n",
            "  0.       0.729718 0.       0.      ]\n",
            " [0.       0.589463 0.       0.       0.       0.475575 0.       0.280882\n",
            "  0.589463 0.       0.       0.      ]\n",
            " [0.589463 0.       0.475575 0.       0.589463 0.       0.       0.280882\n",
            "  0.       0.       0.       0.      ]\n",
            " [0.       0.       0.       0.670092 0.       0.       0.       0.319302\n",
            "  0.       0.       0.670092 0.      ]]\n",
            "Hasil Token\n",
            "['ate' 'away' 'cat' 'end' 'finally' 'house' 'little' 'mouse' 'ran' 'saw'\n",
            " 'story' 'tiny']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = ('/content/drive/MyDrive/MACHINE LEARNING/corpus.txt')\n",
        "\n",
        "with open(data, 'r') as file:\n",
        "    corpus = file.readlines()\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Inisialisasi obyek TFidVectorizer\n",
        "\n",
        "vect= TfidfVectorizer(stop_words='english')\n",
        "\n",
        "# pembobotan tf idf\n",
        "\n",
        "resp = vect.fit_transform(corpus)\n",
        "print(resp)\n",
        "print(resp.toarray())\n",
        "\n",
        "# cetak token hasil stopword\n",
        "print('Hasil Token')\n",
        "print(vect.get_feature_names_out())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qk75avjyr56t",
        "outputId": "561ced83-7d0e-43b5-edb6-8db58f10b60c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 7)\t0.2808823162882302\n",
            "  (0, 6)\t0.5894630806320427\n",
            "  (0, 11)\t0.5894630806320427\n",
            "  (0, 5)\t0.47557510189256375\n",
            "  (1, 9)\t0.7297183669435993\n",
            "  (1, 2)\t0.5887321837696324\n",
            "  (1, 7)\t0.3477147117091919\n",
            "  (2, 1)\t0.5894630806320427\n",
            "  (2, 8)\t0.5894630806320427\n",
            "  (2, 7)\t0.2808823162882302\n",
            "  (2, 5)\t0.47557510189256375\n",
            "  (3, 0)\t0.5894630806320427\n",
            "  (3, 4)\t0.5894630806320427\n",
            "  (3, 2)\t0.47557510189256375\n",
            "  (3, 7)\t0.2808823162882302\n",
            "  (4, 10)\t0.6700917930430479\n",
            "  (4, 3)\t0.6700917930430479\n",
            "  (4, 7)\t0.3193023297639811\n",
            "[[0.       0.       0.       0.       0.       0.475575 0.589463 0.280882\n",
            "  0.       0.       0.       0.589463]\n",
            " [0.       0.       0.588732 0.       0.       0.       0.       0.347715\n",
            "  0.       0.729718 0.       0.      ]\n",
            " [0.       0.589463 0.       0.       0.       0.475575 0.       0.280882\n",
            "  0.589463 0.       0.       0.      ]\n",
            " [0.589463 0.       0.475575 0.       0.589463 0.       0.       0.280882\n",
            "  0.       0.       0.       0.      ]\n",
            " [0.       0.       0.       0.670092 0.       0.       0.       0.319302\n",
            "  0.       0.       0.670092 0.      ]]\n",
            "Hasil Token\n",
            "['ate' 'away' 'cat' 'end' 'finally' 'house' 'little' 'mouse' 'ran' 'saw'\n",
            " 'story' 'tiny']\n"
          ]
        }
      ]
    }
  ]
}